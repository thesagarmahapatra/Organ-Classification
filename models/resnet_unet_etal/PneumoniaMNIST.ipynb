{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQUixvF-yA8T",
    "outputId": "8e514c48-ddae-49e9-af12-549a542495d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wisgqrOdyQ9k",
    "outputId": "fd57547c-fd61-4143-d3ce-69b908ac0f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved and CSV files have been created for train, validation, and test datasets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "dataset_path = '/content/drive/MyDrive/PneumoniaMNIST/pneumoniamnist_224.npz'\n",
    "data = np.load(dataset_path)\n",
    "\n",
    "train_images = data['train_images']\n",
    "train_labels = data['train_labels']\n",
    "val_images = data['val_images']\n",
    "val_labels = data['val_labels']\n",
    "test_images = data['test_images']\n",
    "test_labels = data['test_labels']\n",
    "\n",
    "def save_image_array(image_array, output_path):\n",
    "    image = Image.fromarray(image_array.astype('uint8'))\n",
    "    image.save(output_path)\n",
    "\n",
    "output_dir = '/content/drive/MyDrive/PneumoniaMNIST/images'\n",
    "\n",
    "def create_image_file_paths(images, labels, dataset_type):\n",
    "    image_paths = []\n",
    "    label_list = []\n",
    "\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        image_filename = f'{dataset_type}_image_{i}.png'\n",
    "        image_filepath = os.path.join(output_dir, image_filename)\n",
    "\n",
    "        save_image_array(image, image_filepath)\n",
    "\n",
    "        image_paths.append(image_filepath)\n",
    "        label_list.append(label)\n",
    "\n",
    "    return image_paths, label_list\n",
    "\n",
    "train_image_paths, train_labels_list = create_image_file_paths(train_images, train_labels, 'train')\n",
    "val_image_paths, val_labels_list = create_image_file_paths(val_images, val_labels, 'val')\n",
    "test_image_paths, test_labels_list = create_image_file_paths(test_images, test_labels, 'test')\n",
    "\n",
    "train_df = pd.DataFrame({'image_path': train_image_paths, 'label': train_labels_list})\n",
    "val_df = pd.DataFrame({'image_path': val_image_paths, 'label': val_labels_list})\n",
    "test_df = pd.DataFrame({'image_path': test_image_paths, 'label': test_labels_list})\n",
    "\n",
    "train_df.to_csv('train_dataset.csv', index=False)\n",
    "val_df.to_csv('val_dataset.csv', index=False)\n",
    "test_df.to_csv('test_dataset.csv', index=False)\n",
    "\n",
    "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('combined_dataset.csv', index=False)\n",
    "\n",
    "print(\"Images saved and CSV files have been created for train, validation, and test datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ey1dcQgHzX3N",
    "outputId": "2e217449-16d6-4bd1-b132-aa58b49aec83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.2)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
      "Requirement already satisfied: timm==0.9.7 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.9.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
      "Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision segmentation-models-pytorch pandas pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-d_G2pvKzx49",
    "outputId": "e32fd74e-e63a-4573-ddd2-83ebeb24dab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pandas pillow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VM7sPRiwz1k2",
    "outputId": "73fdb868-0928-4070-b035-93170bc617e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved test_dataset.csv to /content/drive/MyDrive/PneumoniaMNIST/\n",
      "Moved val_dataset.csv to /content/drive/MyDrive/PneumoniaMNIST/\n",
      "Moved train_dataset.csv to /content/drive/MyDrive/PneumoniaMNIST/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "source_dir = \"/content/\" \n",
    "\n",
    "destination_dir = \"/content/drive/MyDrive/PneumoniaMNIST/\"\n",
    "os.makedirs(destination_dir, exist_ok=True)  \n",
    "\n",
    "csv_files = [\"test_dataset.csv\", \"val_dataset.csv\", \"train_dataset.csv\"]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    source_path = os.path.join(source_dir, csv_file)\n",
    "    destination_path = os.path.join(destination_dir, csv_file)\n",
    "\n",
    "    if os.path.exists(source_path):  \n",
    "        shutil.move(source_path, destination_path)\n",
    "        print(f\"Moved {csv_file} to {destination_dir}\")\n",
    "    else:\n",
    "        print(f\"File not found: {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "tce00sXu0AoW",
    "outputId": "e9868088-e55a-4dc2-f7cc-2bfa7fe6cff8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Image not found: /content/drive/MyDrive/PneumoniaMNIST/images/train_image_50.png",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0d130409a13d>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Process train, val, and test datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mprocess_dataset_with_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_updated_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mprocess_dataset_with_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_updated_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprocess_dataset_with_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_updated_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0d130409a13d>\u001b[0m in \u001b[0;36mprocess_dataset_with_masks\u001b[0;34m(csv_path, updated_csv_path, image_dir, mask_dir, threshold)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Generate masks for all images in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     df['mask_path'] = df['image_path'].apply(\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_mask_with_opencv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
      "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0d130409a13d>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# Generate masks for all images in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     df['mask_path'] = df['image_path'].apply(\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_mask_with_opencv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     )\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-0d130409a13d>\u001b[0m in \u001b[0;36mgenerate_mask_with_opencv\u001b[0;34m(image_path, threshold, mask_dir)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image not found: {image_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Apply the threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Image not found: /content/drive/MyDrive/PneumoniaMNIST/images/train_image_50.png"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "image_dir = \"/content/drive/MyDrive/PneumoniaMNIST/images\"  \n",
    "mask_dir = \"/content/drive/MyDrive/PneumoniaMNIST/masks\"    \n",
    "os.makedirs(mask_dir, exist_ok=True)  \n",
    "\n",
    "train_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/train_dataset.csv\"\n",
    "val_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/val_dataset.csv\"\n",
    "test_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/test_dataset.csv\"\n",
    "\n",
    "train_updated_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/train_dataset_with_masks.csv\"\n",
    "val_updated_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/val_dataset_with_masks.csv\"\n",
    "test_updated_csv_path = \"/content/drive/MyDrive/PneumoniaMNIST/test_dataset_with_masks.csv\"\n",
    "\n",
    "def generate_mask_with_opencv(image_path, threshold, mask_dir):\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    _, mask = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask_filename = os.path.basename(image_path).replace(\".png\", \"_mask.png\")\n",
    "    mask_path = os.path.join(mask_dir, mask_filename)\n",
    "    cv2.imwrite(mask_path, mask)\n",
    "\n",
    "    return mask_path\n",
    "\n",
    "def process_dataset_with_masks(csv_path, updated_csv_path, image_dir, mask_dir, threshold):\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df['mask_path'] = df['image_path'].apply(\n",
    "        lambda img_path: generate_mask_with_opencv(os.path.join(image_dir, os.path.basename(img_path)), threshold, mask_dir)\n",
    "    )\n",
    "\n",
    "    df.to_csv(updated_csv_path, index=False)\n",
    "    print(f\"Updated CSV saved to {updated_csv_path}\")\n",
    "\n",
    "threshold = 110\n",
    "\n",
    "process_dataset_with_masks(train_csv_path, train_updated_csv_path, image_dir, mask_dir, threshold)\n",
    "process_dataset_with_masks(val_csv_path, val_updated_csv_path, image_dir, mask_dir, threshold)\n",
    "process_dataset_with_masks(test_csv_path, test_updated_csv_path, image_dir, mask_dir, threshold)\n",
    "\n",
    "print(f\"Masks generated and paths added to train, val, and test datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hvzs-tvNQJI7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.models import resnet34\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "class ClassificationDatasetWithMaskGrayscale(Dataset):\n",
    "    def __init__(self, df, base_image_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.base_image_dir = base_image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.base_image_dir, os.path.basename(row['image_path']))\n",
    "        mask_path = row['mask_path']\n",
    "        label = row['label']\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask)\n",
    "\n",
    "        if mask.dim() == 2:\n",
    "            mask = mask.unsqueeze(0)\n",
    "\n",
    "        image_with_mask = torch.cat((image, mask), dim=0)\n",
    "        label = float(label)\n",
    "\n",
    "        return image_with_mask, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "base_image_dir = \"/content/drive/MyDrive/PneumoniaMNIST/images\"\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/train_dataset.csv')\n",
    "val_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/val_dataset.csv')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/test_dataset.csv')\n",
    "\n",
    "train_df['label'] = train_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "val_df['label'] = val_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "\n",
    "train_dataset = ClassificationDatasetWithMaskGrayscale(train_df, base_image_dir, transforms=data_transforms)\n",
    "val_dataset = ClassificationDatasetWithMaskGrayscale(val_df, base_image_dir, transforms=data_transforms)\n",
    "test_dataset = ClassificationDatasetWithMaskGrayscale(test_df, base_image_dir, transforms=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "class ResNetClassifierWithMaskGrayscale(nn.Module):\n",
    "    def __init__(self, encoder_weights=\"imagenet\"):\n",
    "        super(ResNetClassifierWithMaskGrayscale, self).__init__()\n",
    "        self.encoder = resnet34(weights=\"ResNet34_Weights.IMAGENET1K_V1\" if encoder_weights == \"imagenet\" else None)\n",
    "        self.encoder.conv1 = nn.Conv2d(2, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.encoder = nn.Sequential(*list(self.encoder.children())[:-2])\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        pooled = self.gap(features).view(features.size(0), -1)\n",
    "        output = self.fc(pooled)\n",
    "        return output\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetClassifierWithMaskGrayscale().to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "model.eval()\n",
    "val_labels = []\n",
    "val_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs).squeeze()\n",
    "        val_labels.extend(labels.cpu().numpy())\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "val_preds_binary = (np.array(val_preds) > 0.5).astype(int)\n",
    "val_accuracy = accuracy_score(val_labels, val_preds_binary)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs).squeeze()\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_preds_binary = (np.array(test_preds) > 0.5).astype(int)\n",
    "test_accuracy = accuracy_score(test_labels, test_preds_binary)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0s1S4bKC2EnP",
    "outputId": "b4a11a32-d2cf-48b5-abca-0ce4b7398080"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 281MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.26017281296899764\n",
      "Epoch 2, Loss: 0.14346097245559855\n",
      "Epoch 3, Loss: 0.12288634221432573\n",
      "Epoch 4, Loss: 0.1156041322370707\n",
      "Epoch 5, Loss: 0.10788549247939708\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ClassificationDatasetWithMaskGrayscale(Dataset):\n",
    "    def __init__(self, df, base_image_dir, transforms=None):\n",
    "        self.df = df\n",
    "        self.base_image_dir = base_image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.base_image_dir, os.path.basename(row['image_path']))\n",
    "        mask_path = row['mask_path']\n",
    "        label = row['label']\n",
    "\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            mask = self.transforms(mask).squeeze(0)\n",
    "\n",
    "        mask = mask.unsqueeze(0)\n",
    "        image_with_mask = torch.cat((image, mask), dim=0)\n",
    "\n",
    "        return image_with_mask, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "data_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "base_image_dir = \"/content/drive/MyDrive/PneumoniaMNIST/images\"\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/train_dataset.csv')\n",
    "val_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/val_dataset.csv')\n",
    "test_df = pd.read_csv('/content/drive/MyDrive/PneumoniaMNIST/test_dataset.csv')\n",
    "\n",
    "train_df['label'] = train_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "val_df['label'] = val_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "test_df['label'] = test_df['label'].apply(lambda x: int(x.strip(\"[]\")))\n",
    "\n",
    "train_dataset = ClassificationDatasetWithMaskGrayscale(train_df, base_image_dir, transforms=data_transforms)\n",
    "val_dataset = ClassificationDatasetWithMaskGrayscale(val_df, base_image_dir, transforms=data_transforms)\n",
    "test_dataset = ClassificationDatasetWithMaskGrayscale(test_df, base_image_dir, transforms=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "class UNetClassifier(nn.Module):\n",
    "    def __init__(self, input_channels=2, num_classes=1):\n",
    "        super(UNetClassifier, self).__init__()\n",
    "        self.encoder1 = self.conv_block(input_channels, 64)\n",
    "        self.encoder2 = self.conv_block(64, 128)\n",
    "        self.encoder3 = self.conv_block(128, 256)\n",
    "        self.encoder4 = self.conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.decoder3 = self.conv_block(512 + 256, 256)\n",
    "        self.decoder2 = self.conv_block(256 + 128, 128)\n",
    "        self.decoder1 = self.conv_block(128 + 64, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool(enc1))\n",
    "        enc3 = self.encoder3(self.pool(enc2))\n",
    "        enc4 = self.encoder4(self.pool(enc3))\n",
    "\n",
    "        dec3 = self.decoder3(torch.cat([enc4, enc3], dim=1))\n",
    "        dec2 = self.decoder2(torch.cat([self.pool(dec3), enc2], dim=1))\n",
    "        dec1 = self.decoder1(torch.cat([self.pool(dec2), enc1], dim=1))\n",
    "\n",
    "        output = self.final_conv(dec1)\n",
    "        output = self.global_pool(output)\n",
    "        return output.view(output.size(0), -1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetClassifier().to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs.squeeze(), labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niCBhZVUFzAC",
    "outputId": "5dd61225-c279-4e1f-a0f0-450c54581d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9203\n",
      "ROC-AUC: 0.9984\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "all_true_labels = []\n",
    "all_predicted_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_true_labels.extend(masks.cpu().numpy().flatten())\n",
    "        all_predicted_probs.extend(probs.flatten())\n",
    "\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "all_predicted_probs = np.array(all_predicted_probs)\n",
    "all_true_labels = (all_true_labels > 0.5).astype(int)\n",
    "predicted_classes = (all_predicted_probs > 0.5).astype(int)\n",
    "accuracy = accuracy_score(all_true_labels, predicted_classes)\n",
    "roc_auc = roc_auc_score(all_true_labels, all_predicted_probs)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oi3XPpTLF2WC",
    "outputId": "663b66a1-bc1f-4244-eaa0-c5d9b8f18995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to unet_model.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"unet_model.pth\"  \n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
